{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Intensive - Machine Learning Nanodegree\n",
    "\n",
    "## Week 10. Digit Recognition using TensorFlow and Keras\n",
    "\n",
    "### Objectives    \n",
    "\n",
    "  - Get familar with TensorFlow and Keras\n",
    "  - Built neural networks using TensorFlow and Keras to solve a multiclass classification problem\n",
    "  \n",
    "### Prerequisites\n",
    "  - [numpy](http://www.scipy.org/scipylib/download.html)  \n",
    "  - [matplotlib](http://matplotlib.org/index.html)  \n",
    "  - [tensorflow](https://www.tensorflow.org)\n",
    "  - [keras](https://keras.io) \n",
    "  \n",
    "### Installation  \n",
    "If you haven't installed TensorFlow and Keras, run the commands below for installation:  \n",
    "  - Install TensorFlow: `pip install tensorflow`  \n",
    "  - Install Keras: `pip install keras` (It requires either tensorflow or theano installation)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 | TensorFlow  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowâ„¢ is an open source software library for numerical computation using **data flow graphs**. Nodes in the graph represent mathematical operations, while the graph edges represent the multidimensional data arrays (tensors) communicated between them.   \n",
    "\n",
    "<img src=\"./imgs/graph.png\" width=\"400px\">\n",
    "\n",
    "The flexible architecture allows you to break up the graph into several chunks and run them in parallel across multiple CPUs or GPUs in a desktop, server, or mobile device with a single API. TensorFlow was originally developed by researchers and engineers working on the Google Brain Team within Google's Machine Intelligence research organization for the purposes of conducting machine learning and deep neural networks research, but the system is general enough to be applicable in a wide variety of other domains as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sTWC: \n",
    "Square are variables.\n",
    "Circle are operators.\n",
    "Graphs enables parallelization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Your First Graph and Running it in a Session  \n",
    "\n",
    "The following code creates the graph represented above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.Variable(3, name='x') # tf.Varaible(InitialValue, name)\n",
    "y = tf.Variable(4, name='y')\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_1:0' shape=() dtype=int32>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out x, y, and f. No work has been done yet.\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not getting the output we expect! This is because this code actually does not perform any computation, even though it looks like it does. It just creates a computation graph. In fact, even the variables are not initialized yet. To evaluate this graph, we need to open a TensorFlow **session** and use it to intialize the variables and evaluate `f`. A TensorFlow session takes care of placing the operations onto devices such as CPUs and GPUs and running them, and it holds all the variable values.   \n",
    "\n",
    "The following code creates a session, initializes the variables, and evaluates f, and then closes the session to free up resources.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "sess.close()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One downside of the above code is that we keep repeating `sess.run()`. There is a better way as shown below:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the `with` block, the session is set as the default session. Calling `x.initializer.run()` is equivalent to calling `tf.get_default_session().run(x.initializer)`. Similarly, `f.eval()` is equivalent to calling `tf.get_default_session().run(f)`. This makes the code easier to read. Moreover, the session is automatically closed at the end of the block. \n",
    "\n",
    "Instead of manually running the initializer for every single variable, we can use the `global_variables_initializer()` function. Note that it does not actually perform the initialization immediately, but rather creates a node in the graph that will initialize all variables when it run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside Jupyter or within a Python shell, we can also create an `InteractiveSession`. The only difference from a regular `Session` is that when an `InteractiveSession` is created, it automatically sets itself as the default session, so we don't need to use a `with` block. But you do need to close the session manually when you are done with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "# Use for Jupyter Notebook\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "sess.close()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a TensorFlow program is typically split into two parts: **the first part builds a computation graph, and the decond part runs it**. Writing and running programs in TensorFlow has the following steps:  \n",
    "\n",
    "1. Create Tensors (variables) that are not yet executed/evaluated.   \n",
    "2. Write operations between those Tensors.  \n",
    "3. Initialize Tensors.  \n",
    "4. Create a Session.  \n",
    "5. Run the Session. This will run the operations you'd written above.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Graphs \n",
    "\n",
    "Any node you create is automatically added to the default graph: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each graph seems to be related to an execution plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most cases, this is fine but sometimes you may want to manage multiple independent graphs. You can do this by creating a new Graph and temporarily making it the default graph inside a `with` block, as shown below:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you'll also have to know about **placeholders**. A placeholder is an object whose value you can specify later. To specify values for a placeholder, you can pass in values by using a \"feed dictionary\" (`feed_dict` variable). Below, we create a placeholder for x. This allows us to pass in a number later when we run the session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.int64, name = 'x')\n",
    "print(sess.run(2 * x, feed_dict = {x: 3}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you first define x, you don't have to specify a value for it. A placeholder is simply a variable that you will assign data to only later, when running the session. We say that you feed data to these placeholders when running the session.  \n",
    "\n",
    "Here's what's happening: When you specify the operations needed for a computation, you are telling TensorFlow how to construct a computation graph. The computation graph can have some placeholders whose values you will specify only later. Finally, when you run the session, you are telling TensorFlow to execute the computation graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shape(None, 3) means the data is a matrix, where we can have any number of rows, but must have 3 columns.\n",
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "print(B_val_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Neural Network for MNIST Digit Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **MNIST** database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. The database is also widely used for training and testing in the field of machine learning. It was created by \"re-mixing\" the samples from NIST's original datasets. The creators felt that since NIST's training dataset was taken from American Census Bureau employees, while the testing dataset was taken from American high school students, it was not well-suited for machine learning experiments. Furthermore, the black and white images from NIST were normalized to fit into a 28x28 pixel bounding box and anti-aliased, which introduced grayscale levels.  \n",
    "\n",
    "The MNIST database contains 60,000 training images and 10,000 testing images. Half of the training set and half of the test set were taken from NIST's training dataset, while the other half of the training set and the other half of the test set were taken from NIST's testing dataset. There have been a number of scientific papers on attempts to achieve the lowest error rate; one paper, using a hierarchical system of convolutional neural networks, manages to get an error rate on the MNIST database of 0.23 percent. The original creators of the database keep a list of some of the methods tested on it. In their original paper, they use a support vector machine to get an error rate of 0.8 percent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "def preview_tf_mnist(n):\n",
    "    \"\"\"function to view the training data\"\"\"\n",
    "    plt.imshow(mnist.train.images[n].reshape(28, 28), cmap='gray')\n",
    "    print('True Label:', np.argmax(mnist.train.labels[n]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('True Label:', 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c58b490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preview_tf_mnist(122) #index corresponds to which dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a simple neural network (one without hidden layer as shown below) for this task. The code below builds such a neural network with TensorFlow. \n",
    "\n",
    "<img src=\"./imgs/nn.png\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Num of weights = NumInputLayer * NumOutputLayer = 7840\n",
    "\n",
    "# create new tensorflow session\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# create placeholders for inputs and outputs\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784]) #x is the input to NN. None correspond to number of data points, aka images\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10]) # y_ correspond to label\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10])) # initialize weight as zero. W[0] = all the weights from input neuron 0\n",
    "b = tf.Variable(tf.zeros([10])) # initialize bias as zero\n",
    "\n",
    "# initialize variables into session\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# tf.matmul: matrix multiplication\n",
    "y = tf.matmul(x, W) + b #Does order of x and W matter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-9c27b129dd4b>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define cost function \n",
    "# tf.reduce_mean: Computes the mean of elements across dimensions of a tensor.\n",
    "# tf.nn.softmax_cross_entropy_with_logits: Computes softmax cross entropy between `logits` and `labels` \n",
    "# Multi-class label --> Softmax cross entropy\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradient Descent optimizer\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process iteration:0\n",
      "Process iteration:1\n",
      "Process iteration:2\n",
      "Process iteration:3\n",
      "Process iteration:4\n",
      "Process iteration:5\n",
      "Process iteration:6\n",
      "Process iteration:7\n",
      "Process iteration:8\n",
      "Process iteration:9\n",
      "Process iteration:10\n",
      "Process iteration:11\n",
      "Process iteration:12\n",
      "Process iteration:13\n",
      "Process iteration:14\n",
      "Process iteration:15\n",
      "Process iteration:16\n",
      "Process iteration:17\n",
      "Process iteration:18\n",
      "Process iteration:19\n",
      "Process iteration:20\n",
      "Process iteration:21\n",
      "Process iteration:22\n",
      "Process iteration:23\n",
      "Process iteration:24\n",
      "Process iteration:25\n",
      "Process iteration:26\n",
      "Process iteration:27\n",
      "Process iteration:28\n",
      "Process iteration:29\n",
      "Process iteration:30\n",
      "Process iteration:31\n",
      "Process iteration:32\n",
      "Process iteration:33\n",
      "Process iteration:34\n",
      "Process iteration:35\n",
      "Process iteration:36\n",
      "Process iteration:37\n",
      "Process iteration:38\n",
      "Process iteration:39\n",
      "Process iteration:40\n",
      "Process iteration:41\n",
      "Process iteration:42\n",
      "Process iteration:43\n",
      "Process iteration:44\n",
      "Process iteration:45\n",
      "Process iteration:46\n",
      "Process iteration:47\n",
      "Process iteration:48\n",
      "Process iteration:49\n",
      "Process iteration:50\n",
      "Process iteration:51\n",
      "Process iteration:52\n",
      "Process iteration:53\n",
      "Process iteration:54\n",
      "Process iteration:55\n",
      "Process iteration:56\n",
      "Process iteration:57\n",
      "Process iteration:58\n",
      "Process iteration:59\n",
      "Process iteration:60\n",
      "Process iteration:61\n",
      "Process iteration:62\n",
      "Process iteration:63\n",
      "Process iteration:64\n",
      "Process iteration:65\n",
      "Process iteration:66\n",
      "Process iteration:67\n",
      "Process iteration:68\n",
      "Process iteration:69\n",
      "Process iteration:70\n",
      "Process iteration:71\n",
      "Process iteration:72\n",
      "Process iteration:73\n",
      "Process iteration:74\n",
      "Process iteration:75\n",
      "Process iteration:76\n",
      "Process iteration:77\n",
      "Process iteration:78\n",
      "Process iteration:79\n",
      "Process iteration:80\n",
      "Process iteration:81\n",
      "Process iteration:82\n",
      "Process iteration:83\n",
      "Process iteration:84\n",
      "Process iteration:85\n",
      "Process iteration:86\n",
      "Process iteration:87\n",
      "Process iteration:88\n",
      "Process iteration:89\n",
      "Process iteration:90\n",
      "Process iteration:91\n",
      "Process iteration:92\n",
      "Process iteration:93\n",
      "Process iteration:94\n",
      "Process iteration:95\n",
      "Process iteration:96\n",
      "Process iteration:97\n",
      "Process iteration:98\n",
      "Process iteration:99\n",
      "Process iteration:100\n",
      "Process iteration:101\n",
      "Process iteration:102\n",
      "Process iteration:103\n",
      "Process iteration:104\n",
      "Process iteration:105\n",
      "Process iteration:106\n",
      "Process iteration:107\n",
      "Process iteration:108\n",
      "Process iteration:109\n",
      "Process iteration:110\n",
      "Process iteration:111\n",
      "Process iteration:112\n",
      "Process iteration:113\n",
      "Process iteration:114\n",
      "Process iteration:115\n",
      "Process iteration:116\n",
      "Process iteration:117\n",
      "Process iteration:118\n",
      "Process iteration:119\n",
      "Process iteration:120\n",
      "Process iteration:121\n",
      "Process iteration:122\n",
      "Process iteration:123\n",
      "Process iteration:124\n",
      "Process iteration:125\n",
      "Process iteration:126\n",
      "Process iteration:127\n",
      "Process iteration:128\n",
      "Process iteration:129\n",
      "Process iteration:130\n",
      "Process iteration:131\n",
      "Process iteration:132\n",
      "Process iteration:133\n",
      "Process iteration:134\n",
      "Process iteration:135\n",
      "Process iteration:136\n",
      "Process iteration:137\n",
      "Process iteration:138\n",
      "Process iteration:139\n",
      "Process iteration:140\n",
      "Process iteration:141\n",
      "Process iteration:142\n",
      "Process iteration:143\n",
      "Process iteration:144\n",
      "Process iteration:145\n",
      "Process iteration:146\n",
      "Process iteration:147\n",
      "Process iteration:148\n",
      "Process iteration:149\n",
      "Process iteration:150\n",
      "Process iteration:151\n",
      "Process iteration:152\n",
      "Process iteration:153\n",
      "Process iteration:154\n",
      "Process iteration:155\n",
      "Process iteration:156\n",
      "Process iteration:157\n",
      "Process iteration:158\n",
      "Process iteration:159\n",
      "Process iteration:160\n",
      "Process iteration:161\n",
      "Process iteration:162\n",
      "Process iteration:163\n",
      "Process iteration:164\n",
      "Process iteration:165\n",
      "Process iteration:166\n",
      "Process iteration:167\n",
      "Process iteration:168\n",
      "Process iteration:169\n",
      "Process iteration:170\n",
      "Process iteration:171\n",
      "Process iteration:172\n",
      "Process iteration:173\n",
      "Process iteration:174\n",
      "Process iteration:175\n",
      "Process iteration:176\n",
      "Process iteration:177\n",
      "Process iteration:178\n",
      "Process iteration:179\n",
      "Process iteration:180\n",
      "Process iteration:181\n",
      "Process iteration:182\n",
      "Process iteration:183\n",
      "Process iteration:184\n",
      "Process iteration:185\n",
      "Process iteration:186\n",
      "Process iteration:187\n",
      "Process iteration:188\n",
      "Process iteration:189\n",
      "Process iteration:190\n",
      "Process iteration:191\n",
      "Process iteration:192\n",
      "Process iteration:193\n",
      "Process iteration:194\n",
      "Process iteration:195\n",
      "Process iteration:196\n",
      "Process iteration:197\n",
      "Process iteration:198\n",
      "Process iteration:199\n",
      "Process iteration:200\n",
      "Process iteration:201\n",
      "Process iteration:202\n",
      "Process iteration:203\n",
      "Process iteration:204\n",
      "Process iteration:205\n",
      "Process iteration:206\n",
      "Process iteration:207\n",
      "Process iteration:208\n",
      "Process iteration:209\n",
      "Process iteration:210\n",
      "Process iteration:211\n",
      "Process iteration:212\n",
      "Process iteration:213\n",
      "Process iteration:214\n",
      "Process iteration:215\n",
      "Process iteration:216\n",
      "Process iteration:217\n",
      "Process iteration:218\n",
      "Process iteration:219\n",
      "Process iteration:220\n",
      "Process iteration:221\n",
      "Process iteration:222\n",
      "Process iteration:223\n",
      "Process iteration:224\n",
      "Process iteration:225\n",
      "Process iteration:226\n",
      "Process iteration:227\n",
      "Process iteration:228\n",
      "Process iteration:229\n",
      "Process iteration:230\n",
      "Process iteration:231\n",
      "Process iteration:232\n",
      "Process iteration:233\n",
      "Process iteration:234\n",
      "Process iteration:235\n",
      "Process iteration:236\n",
      "Process iteration:237\n",
      "Process iteration:238\n",
      "Process iteration:239\n",
      "Process iteration:240\n",
      "Process iteration:241\n",
      "Process iteration:242\n",
      "Process iteration:243\n",
      "Process iteration:244\n",
      "Process iteration:245\n",
      "Process iteration:246\n",
      "Process iteration:247\n",
      "Process iteration:248\n",
      "Process iteration:249\n",
      "Process iteration:250\n",
      "Process iteration:251\n",
      "Process iteration:252\n",
      "Process iteration:253\n",
      "Process iteration:254\n",
      "Process iteration:255\n",
      "Process iteration:256\n",
      "Process iteration:257\n",
      "Process iteration:258\n",
      "Process iteration:259\n",
      "Process iteration:260\n",
      "Process iteration:261\n",
      "Process iteration:262\n",
      "Process iteration:263\n",
      "Process iteration:264\n",
      "Process iteration:265\n",
      "Process iteration:266\n",
      "Process iteration:267\n",
      "Process iteration:268\n",
      "Process iteration:269\n",
      "Process iteration:270\n",
      "Process iteration:271\n",
      "Process iteration:272\n",
      "Process iteration:273\n",
      "Process iteration:274\n",
      "Process iteration:275\n",
      "Process iteration:276\n",
      "Process iteration:277\n",
      "Process iteration:278\n",
      "Process iteration:279\n",
      "Process iteration:280\n",
      "Process iteration:281\n",
      "Process iteration:282\n",
      "Process iteration:283\n",
      "Process iteration:284\n",
      "Process iteration:285\n",
      "Process iteration:286\n",
      "Process iteration:287\n",
      "Process iteration:288\n",
      "Process iteration:289\n",
      "Process iteration:290\n",
      "Process iteration:291\n",
      "Process iteration:292\n",
      "Process iteration:293\n",
      "Process iteration:294\n",
      "Process iteration:295\n",
      "Process iteration:296\n",
      "Process iteration:297\n",
      "Process iteration:298\n",
      "Process iteration:299\n",
      "Process iteration:300\n",
      "Process iteration:301\n",
      "Process iteration:302\n",
      "Process iteration:303\n",
      "Process iteration:304\n",
      "Process iteration:305\n",
      "Process iteration:306\n",
      "Process iteration:307\n",
      "Process iteration:308\n",
      "Process iteration:309\n",
      "Process iteration:310\n",
      "Process iteration:311\n",
      "Process iteration:312\n",
      "Process iteration:313\n",
      "Process iteration:314\n",
      "Process iteration:315\n",
      "Process iteration:316\n",
      "Process iteration:317\n",
      "Process iteration:318\n",
      "Process iteration:319\n",
      "Process iteration:320\n",
      "Process iteration:321\n",
      "Process iteration:322\n",
      "Process iteration:323\n",
      "Process iteration:324\n",
      "Process iteration:325\n",
      "Process iteration:326\n",
      "Process iteration:327\n",
      "Process iteration:328\n",
      "Process iteration:329\n",
      "Process iteration:330\n",
      "Process iteration:331\n",
      "Process iteration:332\n",
      "Process iteration:333\n",
      "Process iteration:334\n",
      "Process iteration:335\n",
      "Process iteration:336\n",
      "Process iteration:337\n",
      "Process iteration:338\n",
      "Process iteration:339\n",
      "Process iteration:340\n",
      "Process iteration:341\n",
      "Process iteration:342\n",
      "Process iteration:343\n",
      "Process iteration:344\n",
      "Process iteration:345\n",
      "Process iteration:346\n",
      "Process iteration:347\n",
      "Process iteration:348\n",
      "Process iteration:349\n",
      "Process iteration:350\n",
      "Process iteration:351\n",
      "Process iteration:352\n",
      "Process iteration:353\n",
      "Process iteration:354\n",
      "Process iteration:355\n",
      "Process iteration:356\n",
      "Process iteration:357\n",
      "Process iteration:358\n",
      "Process iteration:359\n",
      "Process iteration:360\n",
      "Process iteration:361\n",
      "Process iteration:362\n",
      "Process iteration:363\n",
      "Process iteration:364\n",
      "Process iteration:365\n",
      "Process iteration:366\n",
      "Process iteration:367\n",
      "Process iteration:368\n",
      "Process iteration:369\n",
      "Process iteration:370\n",
      "Process iteration:371\n",
      "Process iteration:372\n",
      "Process iteration:373\n",
      "Process iteration:374\n",
      "Process iteration:375\n",
      "Process iteration:376\n",
      "Process iteration:377\n",
      "Process iteration:378\n",
      "Process iteration:379\n",
      "Process iteration:380\n",
      "Process iteration:381\n",
      "Process iteration:382\n",
      "Process iteration:383\n",
      "Process iteration:384\n",
      "Process iteration:385\n",
      "Process iteration:386\n",
      "Process iteration:387\n",
      "Process iteration:388\n",
      "Process iteration:389\n",
      "Process iteration:390\n",
      "Process iteration:391\n",
      "Process iteration:392\n",
      "Process iteration:393\n",
      "Process iteration:394\n",
      "Process iteration:395\n",
      "Process iteration:396\n",
      "Process iteration:397\n",
      "Process iteration:398\n",
      "Process iteration:399\n",
      "Process iteration:400\n",
      "Process iteration:401\n",
      "Process iteration:402\n",
      "Process iteration:403\n",
      "Process iteration:404\n",
      "Process iteration:405\n",
      "Process iteration:406\n",
      "Process iteration:407\n",
      "Process iteration:408\n",
      "Process iteration:409\n",
      "Process iteration:410\n",
      "Process iteration:411\n",
      "Process iteration:412\n",
      "Process iteration:413\n",
      "Process iteration:414\n",
      "Process iteration:415\n",
      "Process iteration:416\n",
      "Process iteration:417\n",
      "Process iteration:418\n",
      "Process iteration:419\n",
      "Process iteration:420\n",
      "Process iteration:421\n",
      "Process iteration:422\n",
      "Process iteration:423\n",
      "Process iteration:424\n",
      "Process iteration:425\n",
      "Process iteration:426\n",
      "Process iteration:427\n",
      "Process iteration:428\n",
      "Process iteration:429\n",
      "Process iteration:430\n",
      "Process iteration:431\n",
      "Process iteration:432\n",
      "Process iteration:433\n",
      "Process iteration:434\n",
      "Process iteration:435\n",
      "Process iteration:436\n",
      "Process iteration:437\n",
      "Process iteration:438\n",
      "Process iteration:439\n",
      "Process iteration:440\n",
      "Process iteration:441\n",
      "Process iteration:442\n",
      "Process iteration:443\n",
      "Process iteration:444\n",
      "Process iteration:445\n",
      "Process iteration:446\n",
      "Process iteration:447\n",
      "Process iteration:448\n",
      "Process iteration:449\n",
      "Process iteration:450\n",
      "Process iteration:451\n",
      "Process iteration:452\n",
      "Process iteration:453\n",
      "Process iteration:454\n",
      "Process iteration:455\n",
      "Process iteration:456\n",
      "Process iteration:457\n",
      "Process iteration:458\n",
      "Process iteration:459\n",
      "Process iteration:460\n",
      "Process iteration:461\n",
      "Process iteration:462\n",
      "Process iteration:463\n",
      "Process iteration:464\n",
      "Process iteration:465\n",
      "Process iteration:466\n",
      "Process iteration:467\n",
      "Process iteration:468\n",
      "Process iteration:469\n",
      "Process iteration:470\n",
      "Process iteration:471\n",
      "Process iteration:472\n",
      "Process iteration:473\n",
      "Process iteration:474\n",
      "Process iteration:475\n",
      "Process iteration:476\n",
      "Process iteration:477\n",
      "Process iteration:478\n",
      "Process iteration:479\n",
      "Process iteration:480\n",
      "Process iteration:481\n",
      "Process iteration:482\n",
      "Process iteration:483\n",
      "Process iteration:484\n",
      "Process iteration:485\n",
      "Process iteration:486\n",
      "Process iteration:487\n",
      "Process iteration:488\n",
      "Process iteration:489\n",
      "Process iteration:490\n",
      "Process iteration:491\n",
      "Process iteration:492\n",
      "Process iteration:493\n",
      "Process iteration:494\n",
      "Process iteration:495\n",
      "Process iteration:496\n",
      "Process iteration:497\n",
      "Process iteration:498\n",
      "Process iteration:499\n",
      "Process iteration:500\n",
      "Process iteration:501\n",
      "Process iteration:502\n",
      "Process iteration:503\n",
      "Process iteration:504\n",
      "Process iteration:505\n",
      "Process iteration:506\n",
      "Process iteration:507\n",
      "Process iteration:508\n",
      "Process iteration:509\n",
      "Process iteration:510\n",
      "Process iteration:511\n",
      "Process iteration:512\n",
      "Process iteration:513\n",
      "Process iteration:514\n",
      "Process iteration:515\n",
      "Process iteration:516\n",
      "Process iteration:517\n",
      "Process iteration:518\n",
      "Process iteration:519\n",
      "Process iteration:520\n",
      "Process iteration:521\n",
      "Process iteration:522\n",
      "Process iteration:523\n",
      "Process iteration:524\n",
      "Process iteration:525\n",
      "Process iteration:526\n",
      "Process iteration:527\n",
      "Process iteration:528\n",
      "Process iteration:529\n",
      "Process iteration:530\n",
      "Process iteration:531\n",
      "Process iteration:532\n",
      "Process iteration:533\n",
      "Process iteration:534\n",
      "Process iteration:535\n",
      "Process iteration:536\n",
      "Process iteration:537\n",
      "Process iteration:538\n",
      "Process iteration:539\n",
      "Process iteration:540\n",
      "Process iteration:541\n",
      "Process iteration:542\n",
      "Process iteration:543\n",
      "Process iteration:544\n",
      "Process iteration:545\n",
      "Process iteration:546\n",
      "Process iteration:547\n",
      "Process iteration:548\n",
      "Process iteration:549\n",
      "Process iteration:550\n",
      "Process iteration:551\n",
      "Process iteration:552\n",
      "Process iteration:553\n",
      "Process iteration:554\n",
      "Process iteration:555\n",
      "Process iteration:556\n",
      "Process iteration:557\n",
      "Process iteration:558\n",
      "Process iteration:559\n",
      "Process iteration:560\n",
      "Process iteration:561\n",
      "Process iteration:562\n",
      "Process iteration:563\n",
      "Process iteration:564\n",
      "Process iteration:565\n",
      "Process iteration:566\n",
      "Process iteration:567\n",
      "Process iteration:568\n",
      "Process iteration:569\n",
      "Process iteration:570\n",
      "Process iteration:571\n",
      "Process iteration:572\n",
      "Process iteration:573\n",
      "Process iteration:574\n",
      "Process iteration:575\n",
      "Process iteration:576\n",
      "Process iteration:577\n",
      "Process iteration:578\n",
      "Process iteration:579\n",
      "Process iteration:580\n",
      "Process iteration:581\n",
      "Process iteration:582\n",
      "Process iteration:583\n",
      "Process iteration:584\n",
      "Process iteration:585\n",
      "Process iteration:586\n",
      "Process iteration:587\n",
      "Process iteration:588\n",
      "Process iteration:589\n",
      "Process iteration:590\n",
      "Process iteration:591\n",
      "Process iteration:592\n",
      "Process iteration:593\n",
      "Process iteration:594\n",
      "Process iteration:595\n",
      "Process iteration:596\n",
      "Process iteration:597\n",
      "Process iteration:598\n",
      "Process iteration:599\n",
      "Process iteration:600\n",
      "Process iteration:601\n",
      "Process iteration:602\n",
      "Process iteration:603\n",
      "Process iteration:604\n",
      "Process iteration:605\n",
      "Process iteration:606\n",
      "Process iteration:607\n",
      "Process iteration:608\n",
      "Process iteration:609\n",
      "Process iteration:610\n",
      "Process iteration:611\n",
      "Process iteration:612\n",
      "Process iteration:613\n",
      "Process iteration:614\n",
      "Process iteration:615\n",
      "Process iteration:616\n",
      "Process iteration:617\n",
      "Process iteration:618\n",
      "Process iteration:619\n",
      "Process iteration:620\n",
      "Process iteration:621\n",
      "Process iteration:622\n",
      "Process iteration:623\n",
      "Process iteration:624\n",
      "Process iteration:625\n",
      "Process iteration:626\n",
      "Process iteration:627\n",
      "Process iteration:628\n",
      "Process iteration:629\n",
      "Process iteration:630\n",
      "Process iteration:631\n",
      "Process iteration:632\n",
      "Process iteration:633\n",
      "Process iteration:634\n",
      "Process iteration:635\n",
      "Process iteration:636\n",
      "Process iteration:637\n",
      "Process iteration:638\n",
      "Process iteration:639\n",
      "Process iteration:640\n",
      "Process iteration:641\n",
      "Process iteration:642\n",
      "Process iteration:643\n",
      "Process iteration:644\n",
      "Process iteration:645\n",
      "Process iteration:646\n",
      "Process iteration:647\n",
      "Process iteration:648\n",
      "Process iteration:649\n",
      "Process iteration:650\n",
      "Process iteration:651\n",
      "Process iteration:652\n",
      "Process iteration:653\n",
      "Process iteration:654\n",
      "Process iteration:655\n",
      "Process iteration:656\n",
      "Process iteration:657\n",
      "Process iteration:658\n",
      "Process iteration:659\n",
      "Process iteration:660\n",
      "Process iteration:661\n",
      "Process iteration:662\n",
      "Process iteration:663\n",
      "Process iteration:664\n",
      "Process iteration:665\n",
      "Process iteration:666\n",
      "Process iteration:667\n",
      "Process iteration:668\n",
      "Process iteration:669\n",
      "Process iteration:670\n",
      "Process iteration:671\n",
      "Process iteration:672\n",
      "Process iteration:673\n",
      "Process iteration:674\n",
      "Process iteration:675\n",
      "Process iteration:676\n",
      "Process iteration:677\n",
      "Process iteration:678\n",
      "Process iteration:679\n",
      "Process iteration:680\n",
      "Process iteration:681\n",
      "Process iteration:682\n",
      "Process iteration:683\n",
      "Process iteration:684\n",
      "Process iteration:685\n",
      "Process iteration:686\n",
      "Process iteration:687\n",
      "Process iteration:688\n",
      "Process iteration:689\n",
      "Process iteration:690\n",
      "Process iteration:691\n",
      "Process iteration:692\n",
      "Process iteration:693\n",
      "Process iteration:694\n",
      "Process iteration:695\n",
      "Process iteration:696\n",
      "Process iteration:697\n",
      "Process iteration:698\n",
      "Process iteration:699\n",
      "Process iteration:700\n",
      "Process iteration:701\n",
      "Process iteration:702\n",
      "Process iteration:703\n",
      "Process iteration:704\n",
      "Process iteration:705\n",
      "Process iteration:706\n",
      "Process iteration:707\n",
      "Process iteration:708\n",
      "Process iteration:709\n",
      "Process iteration:710\n",
      "Process iteration:711\n",
      "Process iteration:712\n",
      "Process iteration:713\n",
      "Process iteration:714\n",
      "Process iteration:715\n",
      "Process iteration:716\n",
      "Process iteration:717\n",
      "Process iteration:718\n",
      "Process iteration:719\n",
      "Process iteration:720\n",
      "Process iteration:721\n",
      "Process iteration:722\n",
      "Process iteration:723\n",
      "Process iteration:724\n",
      "Process iteration:725\n",
      "Process iteration:726\n",
      "Process iteration:727\n",
      "Process iteration:728\n",
      "Process iteration:729\n",
      "Process iteration:730\n",
      "Process iteration:731\n",
      "Process iteration:732\n",
      "Process iteration:733\n",
      "Process iteration:734\n",
      "Process iteration:735\n",
      "Process iteration:736\n",
      "Process iteration:737\n",
      "Process iteration:738\n",
      "Process iteration:739\n",
      "Process iteration:740\n",
      "Process iteration:741\n",
      "Process iteration:742\n",
      "Process iteration:743\n",
      "Process iteration:744\n",
      "Process iteration:745\n",
      "Process iteration:746\n",
      "Process iteration:747\n",
      "Process iteration:748\n",
      "Process iteration:749\n",
      "Process iteration:750\n",
      "Process iteration:751\n",
      "Process iteration:752\n",
      "Process iteration:753\n",
      "Process iteration:754\n",
      "Process iteration:755\n",
      "Process iteration:756\n",
      "Process iteration:757\n",
      "Process iteration:758\n",
      "Process iteration:759\n",
      "Process iteration:760\n",
      "Process iteration:761\n",
      "Process iteration:762\n",
      "Process iteration:763\n",
      "Process iteration:764\n",
      "Process iteration:765\n",
      "Process iteration:766\n",
      "Process iteration:767\n",
      "Process iteration:768\n",
      "Process iteration:769\n",
      "Process iteration:770\n",
      "Process iteration:771\n",
      "Process iteration:772\n",
      "Process iteration:773\n",
      "Process iteration:774\n",
      "Process iteration:775\n",
      "Process iteration:776\n",
      "Process iteration:777\n",
      "Process iteration:778\n",
      "Process iteration:779\n",
      "Process iteration:780\n",
      "Process iteration:781\n",
      "Process iteration:782\n",
      "Process iteration:783\n",
      "Process iteration:784\n",
      "Process iteration:785\n",
      "Process iteration:786\n",
      "Process iteration:787\n",
      "Process iteration:788\n",
      "Process iteration:789\n",
      "Process iteration:790\n",
      "Process iteration:791\n",
      "Process iteration:792\n",
      "Process iteration:793\n",
      "Process iteration:794\n",
      "Process iteration:795\n",
      "Process iteration:796\n",
      "Process iteration:797\n",
      "Process iteration:798\n",
      "Process iteration:799\n",
      "Process iteration:800\n",
      "Process iteration:801\n",
      "Process iteration:802\n",
      "Process iteration:803\n",
      "Process iteration:804\n",
      "Process iteration:805\n",
      "Process iteration:806\n",
      "Process iteration:807\n",
      "Process iteration:808\n",
      "Process iteration:809\n",
      "Process iteration:810\n",
      "Process iteration:811\n",
      "Process iteration:812\n",
      "Process iteration:813\n",
      "Process iteration:814\n",
      "Process iteration:815\n",
      "Process iteration:816\n",
      "Process iteration:817\n",
      "Process iteration:818\n",
      "Process iteration:819\n",
      "Process iteration:820\n",
      "Process iteration:821\n",
      "Process iteration:822\n",
      "Process iteration:823\n",
      "Process iteration:824\n",
      "Process iteration:825\n",
      "Process iteration:826\n",
      "Process iteration:827\n",
      "Process iteration:828\n",
      "Process iteration:829\n",
      "Process iteration:830\n",
      "Process iteration:831\n",
      "Process iteration:832\n",
      "Process iteration:833\n",
      "Process iteration:834\n",
      "Process iteration:835\n",
      "Process iteration:836\n",
      "Process iteration:837\n",
      "Process iteration:838\n",
      "Process iteration:839\n",
      "Process iteration:840\n",
      "Process iteration:841\n",
      "Process iteration:842\n",
      "Process iteration:843\n",
      "Process iteration:844\n",
      "Process iteration:845\n",
      "Process iteration:846\n",
      "Process iteration:847\n",
      "Process iteration:848\n",
      "Process iteration:849\n",
      "Process iteration:850\n",
      "Process iteration:851\n",
      "Process iteration:852\n",
      "Process iteration:853\n",
      "Process iteration:854\n",
      "Process iteration:855\n",
      "Process iteration:856\n",
      "Process iteration:857\n",
      "Process iteration:858\n",
      "Process iteration:859\n",
      "Process iteration:860\n",
      "Process iteration:861\n",
      "Process iteration:862\n",
      "Process iteration:863\n",
      "Process iteration:864\n",
      "Process iteration:865\n",
      "Process iteration:866\n",
      "Process iteration:867\n",
      "Process iteration:868\n",
      "Process iteration:869\n",
      "Process iteration:870\n",
      "Process iteration:871\n",
      "Process iteration:872\n",
      "Process iteration:873\n",
      "Process iteration:874\n",
      "Process iteration:875\n",
      "Process iteration:876\n",
      "Process iteration:877\n",
      "Process iteration:878\n",
      "Process iteration:879\n",
      "Process iteration:880\n",
      "Process iteration:881\n",
      "Process iteration:882\n",
      "Process iteration:883\n",
      "Process iteration:884\n",
      "Process iteration:885\n",
      "Process iteration:886\n",
      "Process iteration:887\n",
      "Process iteration:888\n",
      "Process iteration:889\n",
      "Process iteration:890\n",
      "Process iteration:891\n",
      "Process iteration:892\n",
      "Process iteration:893\n",
      "Process iteration:894\n",
      "Process iteration:895\n",
      "Process iteration:896\n",
      "Process iteration:897\n",
      "Process iteration:898\n",
      "Process iteration:899\n",
      "Process iteration:900\n",
      "Process iteration:901\n",
      "Process iteration:902\n",
      "Process iteration:903\n",
      "Process iteration:904\n",
      "Process iteration:905\n",
      "Process iteration:906\n",
      "Process iteration:907\n",
      "Process iteration:908\n",
      "Process iteration:909\n",
      "Process iteration:910\n",
      "Process iteration:911\n",
      "Process iteration:912\n",
      "Process iteration:913\n",
      "Process iteration:914\n",
      "Process iteration:915\n",
      "Process iteration:916\n",
      "Process iteration:917\n",
      "Process iteration:918\n",
      "Process iteration:919\n",
      "Process iteration:920\n",
      "Process iteration:921\n",
      "Process iteration:922\n",
      "Process iteration:923\n",
      "Process iteration:924\n",
      "Process iteration:925\n",
      "Process iteration:926\n",
      "Process iteration:927\n",
      "Process iteration:928\n",
      "Process iteration:929\n",
      "Process iteration:930\n",
      "Process iteration:931\n",
      "Process iteration:932\n",
      "Process iteration:933\n",
      "Process iteration:934\n",
      "Process iteration:935\n",
      "Process iteration:936\n",
      "Process iteration:937\n",
      "Process iteration:938\n",
      "Process iteration:939\n",
      "Process iteration:940\n",
      "Process iteration:941\n",
      "Process iteration:942\n",
      "Process iteration:943\n",
      "Process iteration:944\n",
      "Process iteration:945\n",
      "Process iteration:946\n",
      "Process iteration:947\n",
      "Process iteration:948\n",
      "Process iteration:949\n",
      "Process iteration:950\n",
      "Process iteration:951\n",
      "Process iteration:952\n",
      "Process iteration:953\n",
      "Process iteration:954\n",
      "Process iteration:955\n",
      "Process iteration:956\n",
      "Process iteration:957\n",
      "Process iteration:958\n",
      "Process iteration:959\n",
      "Process iteration:960\n",
      "Process iteration:961\n",
      "Process iteration:962\n",
      "Process iteration:963\n",
      "Process iteration:964\n",
      "Process iteration:965\n",
      "Process iteration:966\n",
      "Process iteration:967\n",
      "Process iteration:968\n",
      "Process iteration:969\n",
      "Process iteration:970\n",
      "Process iteration:971\n",
      "Process iteration:972\n",
      "Process iteration:973\n",
      "Process iteration:974\n",
      "Process iteration:975\n",
      "Process iteration:976\n",
      "Process iteration:977\n",
      "Process iteration:978\n",
      "Process iteration:979\n",
      "Process iteration:980\n",
      "Process iteration:981\n",
      "Process iteration:982\n",
      "Process iteration:983\n",
      "Process iteration:984\n",
      "Process iteration:985\n",
      "Process iteration:986\n",
      "Process iteration:987\n",
      "Process iteration:988\n",
      "Process iteration:989\n",
      "Process iteration:990\n",
      "Process iteration:991\n",
      "Process iteration:992\n",
      "Process iteration:993\n",
      "Process iteration:994\n",
      "Process iteration:995\n",
      "Process iteration:996\n",
      "Process iteration:997\n",
      "Process iteration:998\n",
      "Process iteration:999\n"
     ]
    }
   ],
   "source": [
    "# train the neural net for 1000 iterations\n",
    "for i in range(1000):\n",
    "    #print(\"Process iteration:{}\".format(i))\n",
    "    batch = mnist.train.next_batch(100) # mini-batch\n",
    "    #x and y_ are defined as placeHolders. x and y_ are used in (1)matrix multiplication (2) cross entryopy  For each iteration, we get a new set of vlaues.\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.9225)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the performance\n",
    "correct_prediction = tf.equal(tf.argmax(y, axis=1), tf.argmax(y_, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is not too bad. We obtain 92% accuracy for a 10 class classification problem in less than 15 lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow Takeaways\n",
    "\n",
    "- Tensorflow is a programming framework used in deep learning  \n",
    "- The two main object classes in tensorflow are Tensors and Operators. When you code in tensorflow you have to take the following steps:  \n",
    "    1. Create a graph containing Tensors (Variables, Placeholders ...) and Operations (tf.matmul, tf.add, ...)  \n",
    "    2. Create a session  \n",
    "    3. Initialize the session  \n",
    "    4. Run the session to execute the graph  \n",
    "- You can execute the graph multiple times\n",
    "- The backpropagation and optimization is automatically done when running the session on the \"optimizer\" object  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 | Keras \n",
    "\n",
    "Keras is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano. It was developed with a focus on enabling fast experimentation. Being able to go from idea to result with the least possible delay is key to doing good research.\n",
    "\n",
    "Use Keras if you need a deep learning library that:\n",
    "  - Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n",
    "  - Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n",
    "  - Runs seamlessly on CPU and GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the same neural network with Keras and see how it compares with TensorFlow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to define the model architecture, the first step is to declare a sequential model format. `Sequential` model type is simply a linear stack of neural network layers. Then, we can declare the input layer. Here, `Dense` is one of Keras' core layers. It is the regular densely-connected neural network layer. We can simply add more layers to our model like we're building legos using `model.add()`. Finally, we can define the loss function and the optimizer, and then we'll be ready to train it.\n",
    "\n",
    "We can view the model architecture using `model.summary()`. \n",
    "\n",
    "Note that in actual R&D work, researchers will spend a considerable amount of time studying model architectures. But as we're just starting out, we can just replicate proven architectures from academic papers or use existing examples. Here's a list of [example implementations in Keras](https://github.com/fchollet/keras/tree/master/examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # declare a sequential model format \n",
    "model.add(Dense(10, input_dim=784, activation='softmax')) # declare the input layer\n",
    "sgd = SGD(lr=0.5) # define optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy']) # configures the learning process\n",
    "print(model.summary()) # check the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanfeiwu/anaconda/envs/mlnd/lib/python2.7/site-packages/keras/models.py:844: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 0s - loss: 0.4008 - acc: 0.8849 - val_loss: 0.3103 - val_acc: 0.9104\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 0s - loss: 0.3115 - acc: 0.9122 - val_loss: 0.2914 - val_acc: 0.9161\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 0s - loss: 0.2953 - acc: 0.9165 - val_loss: 0.2853 - val_acc: 0.9166\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 0s - loss: 0.2870 - acc: 0.9191 - val_loss: 0.2754 - val_acc: 0.9240\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 0s - loss: 0.2824 - acc: 0.9212 - val_loss: 0.2817 - val_acc: 0.9204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1203df790>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trains the model for a fixed number of epochs\n",
    "model.fit(mnist.train.images, mnist.train.labels, batch_size=100, nb_epoch=5, \n",
    "          validation_data=(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.9204)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the performance\n",
    "score = model.evaluate(mnist.test.images, mnist.test.labels, verbose=0)\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we get the same performance but with half amount of code. Building neural networks in Keras is just as easy as scikit-learn. In fact, keras provides an interface with scikit-learn, so that you can use neural networks just like any other ML algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE \n",
    "\n",
    "Use Keras to build a more complicated neural network. For example, the neural network built with the code below has one hidden layers. Run the cells below to see whether the performance improves. Build your own neural network. What is the architecture of your new model and what is the performance? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # declare a sequential model format \n",
    "model.add(Dense(64, input_dim=784, activation='relu')) # declare the input layer\n",
    "model.add(Dense(10, input_dim=64, activation='softmax')) # declare the hidden layer\n",
    "sgd = SGD(lr=0.5) # define optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy']) # configures the learning process\n",
    "print(model.summary()) # check the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 1s - loss: 0.3100 - acc: 0.9055 - val_loss: 0.1450 - val_acc: 0.9567\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 0s - loss: 0.1382 - acc: 0.9590 - val_loss: 0.1180 - val_acc: 0.9632\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 0s - loss: 0.1030 - acc: 0.9688 - val_loss: 0.1074 - val_acc: 0.9660\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 0s - loss: 0.0840 - acc: 0.9736 - val_loss: 0.0908 - val_acc: 0.9724\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 0s - loss: 0.0708 - acc: 0.9782 - val_loss: 0.0885 - val_acc: 0.9720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11d80dcd0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(mnist.train.images, mnist.train.labels, batch_size=100, nb_epoch=5, \n",
    "          validation_data=(mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy:', 0.97199999999999998)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(mnist.test.images, mnist.test.labels, verbose=0)\n",
    "print('Accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started iteration=0\n",
      "Finished iteration=0\n",
      "Started iteration=100\n",
      "Finished iteration=100\n",
      "Started iteration=200\n",
      "Finished iteration=200\n",
      "Started iteration=300\n",
      "Finished iteration=300\n",
      "Started iteration=400\n",
      "Finished iteration=400\n",
      "Started iteration=500\n",
      "Finished iteration=500\n",
      "Started iteration=600\n",
      "Finished iteration=600\n",
      "Started iteration=700\n",
      "Finished iteration=700\n",
      "Started iteration=800\n",
      "Finished iteration=800\n",
      "Started iteration=900\n",
      "Finished iteration=900\n",
      "Finished training!\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "[False False False ... False False  True]\n",
      "('Accuracy:', 0.0958)\n"
     ]
    }
   ],
   "source": [
    "# Start of my code on a hidden layer\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "n_input = 784 # Because input is an image of size 28*28\n",
    "n_hidden = 40\n",
    "n_output = 10 # Because we have 10 labels\n",
    "\n",
    "x_input = tf.placeholder(tf.float32, shape=[None, n_input])\n",
    "y_label = tf.placeholder(tf.float32, shape=[None, n_output])\n",
    "\n",
    "W_input = tf.Variable(tf.zeros([n_input, n_hidden]))\n",
    "b_input = tf.Variable(tf.zeros([n_hidden]))\n",
    "#y_input = tf.matmul(x_input, W_input) + b_input # y_input is a matrix of size [None, 40] because (x_input=[None, 784] * W_input=[784, 40])\n",
    "y_input = tf.nn.relu(tf.matmul(x_input, W_input) + b_input)\n",
    "\n",
    "\n",
    "W_hidden = tf.Variable(tf.zeros([n_hidden, n_output]))\n",
    "b_hidden = tf.Variable(tf.zeros([n_output]))\n",
    "y_prediction = tf.matmul(y_input, W_hidden) + b_hidden # y_input is a matrix of size [None, 10] because (y_input=[None,40] * W_hidden=[40,10])\n",
    "\n",
    "# Aka loss function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_prediction, labels=y_label))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cross_entropy)\n",
    "\n",
    "# initialize variables into session\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(1000):\n",
    "    if i%100 == 0:\n",
    "        print(\"Started iteration={}\".format(i))\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    train_step.run(feed_dict={x_input:batch[0], y_label:batch[1]}) #feed_dict maps to PlaceHolders\n",
    "    if i%100 == 0:\n",
    "        print(\"Finished iteration={}\".format(i))\n",
    "    \n",
    "print(\"Finished training!\")\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_prediction, axis=1), tf.argmax(y_label, axis=1))\n",
    "\n",
    "print(type(correct_prediction))\n",
    "print(sess.run(correct_prediction, feed_dict={x_input: mnist.test.images, y_label: mnist.test.labels}))# OR Session.run()\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', accuracy.eval(feed_dict={x_input: mnist.test.images, y_label: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started iteration=0\n",
      "Finished iteration=0\n",
      "Started iteration=100\n",
      "Finished iteration=100\n",
      "Started iteration=200\n",
      "Finished iteration=200\n",
      "Started iteration=300\n",
      "Finished iteration=300\n",
      "Started iteration=400\n",
      "Finished iteration=400\n",
      "Started iteration=500\n",
      "Finished iteration=500\n",
      "Started iteration=600\n",
      "Finished iteration=600\n",
      "Started iteration=700\n",
      "Finished iteration=700\n",
      "Started iteration=800\n",
      "Finished iteration=800\n",
      "Started iteration=900\n",
      "Finished iteration=900\n",
      "Finished training!\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "[ True  True  True ...  True  True  True]\n",
      "('Accuracy:', 0.9186)\n"
     ]
    }
   ],
   "source": [
    "# Start of my code on a hidden layer\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "n_input = 784 # Because input is an image of size 28*28\n",
    "n_output = 10 # Because we have 10 labels\n",
    "\n",
    "x_input = tf.placeholder(tf.float32, shape=[None, n_input])\n",
    "y_label = tf.placeholder(tf.float32, shape=[None, n_output])\n",
    "\n",
    "W_hidden = tf.Variable(tf.zeros([n_input, n_output]))\n",
    "b_hidden = tf.Variable(tf.zeros([n_output]))\n",
    "y_prediction = tf.matmul(x_input, W_hidden) # y_input is a matrix of size [None, 10] because (y_input=[None,40] * W_hidden=[40,10])\n",
    "\n",
    "# Aka loss function\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_prediction, labels=y_label))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cross_entropy)\n",
    "\n",
    "# initialize variables into session\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(1000):\n",
    "    if i%100 == 0:\n",
    "        print(\"Started iteration={}\".format(i))\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    train_step.run(feed_dict={x_input:batch[0], y_label:batch[1]}) #feed_dict maps to PlaceHolders\n",
    "    if i%100 == 0:\n",
    "        print(\"Finished iteration={}\".format(i))\n",
    "    \n",
    "print(\"Finished training!\")\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_prediction, axis=1), tf.argmax(y_label, axis=1))\n",
    "\n",
    "print(type(correct_prediction))\n",
    "print(sess.run(correct_prediction, feed_dict={x_input: mnist.test.images, y_label: mnist.test.labels}))# OR Session.run()\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', accuracy.eval(feed_dict={x_input: mnist.test.images, y_label: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working CODE of 2 Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Step 0, training batch accuracy 12 %\n",
      "Step 100, training batch accuracy 90 %\n",
      "Step 200, training batch accuracy 85 %\n",
      "Step 300, training batch accuracy 92 %\n",
      "Step 400, training batch accuracy 93 %\n",
      "Step 500, training batch accuracy 92 %\n",
      "Step 600, training batch accuracy 95 %\n",
      "Step 700, training batch accuracy 91 %\n",
      "Step 800, training batch accuracy 92 %\n",
      "Step 900, training batch accuracy 95 %\n",
      "The end of training!\n",
      "Test accuracy: 94.09 %\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "def train_network(training_data, labels, output, keep_prob=tf.placeholder(tf.float32)):\n",
    "    learning_rate = 1e-4\n",
    "    steps_number = 1000\n",
    "    batch_size = 100\n",
    "\n",
    "    # Read data\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "    # Define the loss function\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=output))\n",
    "\n",
    "    # Training step\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "    # Accuracy calculation\n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    # Run the training\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(steps_number):\n",
    "        # Get the next batch\n",
    "        input_batch, labels_batch = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # Print the accuracy progress on the batch every 100 steps\n",
    "        if i%100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={training_data: input_batch, labels: labels_batch, keep_prob: 1.0})\n",
    "            print(\"Step %d, training batch accuracy %g %%\"%(i, train_accuracy*100))\n",
    "\n",
    "        # Run the training step\n",
    "        train_step.run(feed_dict={training_data: input_batch, labels: labels_batch, keep_prob: 0.5})\n",
    "\n",
    "    print(\"The end of training!\")\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    test_accuracy = accuracy.eval(feed_dict={training_data: mnist.test.images, labels: mnist.test.labels, keep_prob: 1.0})\n",
    "    print(\"Test accuracy: %g %%\"%(test_accuracy*100))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "image_size = 28\n",
    "labels_size = 10\n",
    "hidden_size = 1024\n",
    "\n",
    "# Define placeholders, used for input into simulation.\n",
    "# Placeholders are assiged values via feed_dict, like this: train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "training_data = tf.placeholder(tf.float32, [None, image_size*image_size])\n",
    "labels = tf.placeholder(tf.float32, [None, labels_size])\n",
    "\n",
    "# Variables for the hidden layer\n",
    "W_input = tf.Variable(tf.truncated_normal([image_size*image_size, hidden_size], stddev=0.1))\n",
    "b_input = tf.Variable(tf.constant(0.1, shape=[hidden_size]))\n",
    "\n",
    "# Hidden layer with reLU activation function\n",
    "y_input = tf.nn.relu(tf.matmul(training_data, W_input) + b_input)\n",
    "\n",
    "# Variables for the output layer\n",
    "W = tf.Variable(tf.truncated_normal([hidden_size, labels_size], stddev=0.1))\n",
    "b = tf.Variable(tf.constant(0.1, shape=[labels_size]))\n",
    "\n",
    "# Connect hidden to the output layer\n",
    "output = tf.matmul(y_input, W) + b\n",
    "\n",
    "# Train & test the network\n",
    "train_network(training_data, labels, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordVec_basic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import random\n",
    "from tempfile import gettempdir\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common word = [('blue', 2)]\n",
      "After 1 iteration, count=[['UNK', -1], ('blue', 2), ('yellow', 1), ('red', 1)]\n",
      "data=[1, 1, 3, 2]\n",
      "count=[['UNK', 0], ('blue', 2), ('yellow', 1), ('red', 1)]\n",
      "dictionary={'blue': 1, 'UNK': 0, 'red': 3, 'yellow': 2}\n",
      "reversed_dictionary={0: 'UNK', 1: 'blue', 2: 'yellow', 3: 'red'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tally the count of the words. Method def build_dataset(words, n_words):\n",
    "import collections\n",
    "count = [['UNK', -1]] # 2 dimen matrix of words and their frequency\n",
    "n_words = 10 #Keep top n word for each iteration\n",
    "words = ['blue', 'blue', 'red', 'yellow']\n",
    "wordCnt = collections.Counter(words)\n",
    "mostComonWord = wordCnt.most_common(1)\n",
    "print(\"Most common word = {}\".format(mostComonWord))\n",
    "count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "print(\"After 1 iteration, count={}\".format(count))\n",
    "\n",
    "dictionary = dict()\n",
    "for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "data = list()\n",
    "unk_count = 0\n",
    "for word in words:\n",
    "    index = dictionary.get(word, 0)\n",
    "    if index == 0:  # dictionary['UNK']\n",
    "      unk_count += 1\n",
    "    data.append(index)\n",
    "count[0][1] = unk_count\n",
    "reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "\n",
    "print(\"data={}\\ncount={}\\ndictionary={}\\nreversed_dictionary={}\\n\".format(data, count, dictionary, reversed_dictionary))\n",
    "\n",
    "\n",
    "def build_dataset(words, n_words):\n",
    "  \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "  count = [['UNK', -1]] # 2 dimensional array\n",
    "  count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "  dictionary = dict()\n",
    "  for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "  data = list()\n",
    "  unk_count = 0\n",
    "  for word in words:\n",
    "    index = dictionary.get(word, 0)\n",
    "    if index == 0:  # dictionary['UNK']\n",
    "      unk_count += 1\n",
    "    data.append(index)\n",
    "  count[0][1] = unk_count\n",
    "  reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "  return data, count, dictionary, reversed_dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified text8.zip\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'println' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e80cddbcf837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mprintln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Step 3: Function to generate a training batch for the skip-gram model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'println' is not defined"
     ]
    }
   ],
   "source": [
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "\n",
    "# Step 1: Download the data.\n",
    "url = 'http://mattmahoney.net/dc/'\n",
    "\n",
    "\n",
    "# pylint: disable=redefined-outer-name\n",
    "def maybe_download(filename, expected_bytes):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  local_filename = os.path.join(gettempdir(), filename)\n",
    "  if not os.path.exists(local_filename):\n",
    "    local_filename, _ = urllib.request.urlretrieve(url + filename,\n",
    "                                                   local_filename)\n",
    "  statinfo = os.stat(local_filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', filename)\n",
    "  else:\n",
    "    print(statinfo.st_size)\n",
    "    raise Exception('Failed to verify ' + local_filename +\n",
    "                    '. Can you get to it with a browser?')\n",
    "  return local_filename\n",
    "\n",
    "filename = maybe_download('text8.zip', 31344016)\n",
    "data_index = 0\n",
    "\n",
    "def read_data(filename):\n",
    "  \"\"\"Extract the first file enclosed in a zip file as a list of words.\"\"\"\n",
    "  with zipfile.ZipFile(filename) as f:\n",
    "    data = tf.compat.as_str(f.read(f.namelist()[0])).split()\n",
    "  return data\n",
    "\n",
    "\n",
    "vocabulary = read_data(filename)\n",
    "print('Data size', len(vocabulary))\n",
    "\n",
    "# Step 3: Function to generate a training batch for the skip-gram model.\n",
    "def generate_batch(batch_size, num_skips, skip_window):\n",
    "  global data_index\n",
    "  assert batch_size % num_skips == 0\n",
    "  #assert num_skips <= 2 * skip_window\n",
    "  batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "  labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "  span = 2 * skip_window + 1  # [ skip_window target skip_window ]\n",
    "  buffer = collections.deque(maxlen=span)\n",
    "  if data_index + span > len(data):\n",
    "    data_index = 0\n",
    "  buffer.extend(data[data_index:data_index + span])\n",
    "  data_index += span\n",
    "  for i in range(batch_size // num_skips):\n",
    "    context_words = [w for w in range(span) if w != skip_window]\n",
    "    words_to_use = random.sample(context_words, num_skips)\n",
    "    for j, context_word in enumerate(words_to_use):\n",
    "      batch[i * num_skips + j] = buffer[skip_window]\n",
    "      labels[i * num_skips + j, 0] = buffer[context_word]\n",
    "    if data_index == len(data):\n",
    "      buffer.extend(data[0:span])\n",
    "      data_index = span\n",
    "    else:\n",
    "      buffer.append(data[data_index])\n",
    "      data_index += 1\n",
    "  # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "  data_index = (data_index + len(data) - span) % len(data)\n",
    "  return batch, labels\n",
    "\n",
    "batch_size=100\n",
    "num_skips = 1\n",
    "skip_window=2\n",
    "generate_batch(batch_size, num_skips, skip_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
