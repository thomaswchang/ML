{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect Intensive - Machine Learning Nanodegree\n",
    "\n",
    "## Week 4. Neural Nets Mini-project\n",
    "\n",
    "### Objectives    \n",
    "\n",
    "- Understand the fundamentals of neural networks  \n",
    "- Build simple perceptrons \n",
    "- Train a perceptron model with `scikit-learn` (Optional)\n",
    "\n",
    "### Prerequisites   \n",
    "\n",
    " - You should have [numpy](http://www.scipy.org/scipylib/download.html) and [scikit-learn](http://scikit-learn.org) installed  \n",
    " - You should have some understanding of [Python classes and objects](https://docs.python.org/3/tutorial/classes.html). If you are not familar with these, here is an interactive [tutorial](https://www.learnpython.org/en/Classes_and_Objects).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I. Introduction to Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An [\"Artificial\" Neural Network (ANN)](https://en.wikipedia.org/wiki/Artificial_neural_network) is a computing system made up of a number of simple, highly interconnected processing elements, which process information by their dynamic state response to external inputs. It is inspired by the way biological neural networks in the human brain. ANNs have generated a lot of excitement in the Machine Learning research and industry with great breakthroughs in the areas of speech recognition, computer vision, and natural language processing.  \n",
    "\n",
    "Neural neworks are typically organized in layers. Layers are made up of a number of interconnected **\"nodes\"** which contain an **\"activation function\"**. Patterns are presented to the network via the **\"input layer\"**, which passes through one or more **\"hidden layers\"** to be processed. The hidden layers then connects to an **\"output layer\"** to give the outputs. The image below shows the first and the simplest neural network, the so-called [feedforward neural network](https://en.wikipedia.org/wiki/Feedforward_neural_network), wherein connections between the units do not form a cycle.  \n",
    "\n",
    "![NN](./img/NN.png)\n",
    "\n",
    "### Node (Single Neuron)   \n",
    "The basic unit in a neural network is the neuron, often called a \"node\" or \"unit\". It receives input from some other nodes, or from an external source and computes the output. Each input has an associated *weight (w)*, which is assigned based on its relative importance to other inputs. The node applies a non-linear activation function to the weighted sum of its inputs, as follows, $$f(w_1*x_1 + w_2*x_2 + b)$$. \n",
    "\n",
    "\n",
    "### Activation Function \n",
    "The activation function takes a single number input and performs a certain mathematical operation. Some commonly used activation functions include:  \n",
    "\n",
    "- [Sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function): taks a real-value input and gives a characteristic \"S\"-shaped curve with returned values between 0 and 1  \n",
    "- Tanh: takes a real-valued input and gives output in the range [-1, 1] \n",
    "- [ReLu (**RE**ctified **L**inear **U**nit)](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)): takes a real-valued input and thresholds it at zero (replaces negative values with zero).   \n",
    "\n",
    "\n",
    "### Perceptron  \n",
    "[Perceptron](https://en.wikipedia.org/wiki/Perceptron) was invented in the 1950s and was one of the first artificial neural networks to be produced. \n",
    "\n",
    "- **Single Layer Perceptron** This is the simplest feedforward neural network and does not contain any hidden layer.  \n",
    "\n",
    "- **Multi Layer Perceptron** A Multi Layer Perceptron has one or more hidden layers. It is more useful than Single Layer Perceptons in terms of practical applications.\n",
    "\n",
    "In this notebook, we will be building both a Single Layer Percepton and a Multi Layer Percepton. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II. Build Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Single Layer Perceptron  \n",
    "\n",
    "Note that a simple Single Layer Perceptron maps a series of inputs to an output. Each input is assigned a cetrain weight and then some mapping is applied to determines the output of the perceptron.   \n",
    "\n",
    "![single layer](./img/SL_perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a simple perceptron  \n",
    "We will compute the weights of the inputs by taking the dot product of the input vector and the weight vector. This number is also known as the strenth or the activity of the inputs. We will use a simple step function to map to the perceptron output. The step function takes in the strenth of the inputs and we will compare the strength to some predefined threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------\n",
    "# \n",
    "# In this exercise, you will add in code that decides whether a perceptron will fire based\n",
    "# on the threshold.  \n",
    "#\n",
    "# ----------\n",
    "import numpy as np\n",
    "\n",
    "class Perceptron0(object):\n",
    "    \"\"\"\n",
    "    This class models an artificial neuron with step activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self, weights = np.array([1]), threshold = 0):\n",
    "        \"\"\"\n",
    "        Initialize weights and threshold based on input arguments. Note that no\n",
    "        type-checking is being performed here for simplicity.\n",
    "        \"\"\"\n",
    "        self.weights = weights\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def activate(self, inputs):\n",
    "        \"\"\"\n",
    "        Takes in \n",
    "        @param inputs, a list of numbers equal to length of weights.\n",
    "        @return the output of a threshold perceptron with given inputs based on\n",
    "        perceptron weights and threshold.\n",
    "        \"\"\" \n",
    "\n",
    "        # TODO: calculate the strength with which the perceptron fires.\n",
    "        strength = np.dot(self.weights, inputs)\n",
    "        \n",
    "        # TODO: return 0 or 1 based on the threshold\n",
    "        if strength > self.threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "\n",
    "def test():\n",
    "    \"\"\"\n",
    "    A few tests to make sure that the perceptron class performs as expected.\n",
    "    Nothing should show up in the output if all the assertions pass.\n",
    "    \"\"\"\n",
    "    p1 = Perceptron0(np.array([1, 2]), 0.)\n",
    "    assert p1.activate(np.array([ 1, -1])) == 0 # <threshold -> 0\n",
    "    assert p1.activate(np.array([-1,  1])) == 1 # >threshold -> 1\n",
    "    assert p1.activate(np.array([ 2, -1])) == 0 # =threshold -> 0\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUESTIONS: \n",
    "\n",
    "\n",
    "- What are the advantages of using some threshold and step function rather than just outputting the weighted inputs (dot product)?  \n",
    "> **Answer:**   The threshold can be used as a mapping function. It can be used like an encoder.\n",
    "\n",
    "\n",
    "\n",
    "- What parameter is learnable in a perceptron, i.e., what can be modified to allow the perceptron to model an arbitrary function?   \n",
    "> **Answer:** The weight and threshold are learnable.\n",
    "\n",
    "\n",
    "\n",
    "- What does the input to a network of perceptrons look like? \n",
    "\n",
    "    A) Tensor of weights  \n",
    "    B) Matrix of numerical values  \n",
    "    C) Matrix of classifcations  \n",
    "    D) Matrix of numerical values and classifications for each row.    \n",
    "> **Answer:**  \n",
    "\n",
    "\n",
    "- Are Neural Networks used for classification or regression?   \n",
    "> **Answer:** It could be \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron update rule \n",
    "\n",
    "The update rule for perceptron is as follows:  \n",
    "\n",
    "$$ w(t + 1) = w(t) + (\\eta * (y_i - \\hat{y_i}(t)) * x_i $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 1\n",
      "2 1\n"
     ]
    }
   ],
   "source": [
    "sample = np.array([1, 1, 1])\n",
    "for i,j in enumerate(sample):\n",
    "    print \"{} {}\".format(i, j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y[i] - y_hat = 1\n",
      "y[i] - y_hat = -1\n",
      "y[i] - y_hat = 0\n",
      "y[i] - y_hat = -1\n",
      "y[i] - y_hat = 1\n",
      "y[i] - y_hat = -1\n"
     ]
    }
   ],
   "source": [
    "# ----------\n",
    "#\n",
    "# In this exercise, you will update the perceptron class so that it can update\n",
    "# its weights.\n",
    "#\n",
    "# Finish writing the update() method so that it updates the weights according\n",
    "# to the perceptron update rule. Updates should be performed online, revising\n",
    "# the weights after each data point.\n",
    "# \n",
    "# ----------\n",
    "\n",
    "\n",
    "class Perceptron1(Perceptron0):\n",
    "    \"\"\"\n",
    "    This class models an artificial neuron with step activation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args):\n",
    "        \"\"\"\n",
    "        Initialize weights and threshold based on input arguments. Note that no\n",
    "        type-checking is being performed here for simplicity.\n",
    "        \"\"\"\n",
    "        super(Perceptron1, self).__init__(*args)\n",
    "\n",
    "\n",
    "    def update(self, X, y, eta=.1):\n",
    "        \"\"\"\n",
    "        Takes in \n",
    "        @param X, a 2D array consisting of a LIST of inputs and \n",
    "        @param y, a 1D array consisting of a corresponding list of expected\n",
    "        outputs. Updates internal weights according to the perceptron training\n",
    "        rule using these values and \n",
    "        @param eta, an optional learning rate.\n",
    "        \"\"\"\n",
    "        learningRate = eta\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        # TODO: for each data point... Iterate over each x_i\n",
    "        for i, x_i in enumerate(X):\n",
    "            \n",
    "            # TODO: obtain the prediction for that point\n",
    "            y_hat = self.activate(x_i)\n",
    "\n",
    "            delta = y[i] - y_hat\n",
    "            print \"y[i] - y_hat = {}\".format(delta)\n",
    "                                              \n",
    "            # TODO: update self.weights based on prediction accuracy, learning\n",
    "            # Implement this: w(t+1)=w(t)+(η∗(yi−yi^(t))∗xi\n",
    "            self.weights = self.weights + ((y[i] - y_hat) * learningRate) * x_i\n",
    "                \n",
    "            \n",
    "def test():\n",
    "    \"\"\"\n",
    "    A few tests to make sure that the perceptron class performs as expected.\n",
    "    Nothing should show up in the output if all the assertions pass.\n",
    "    \"\"\"\n",
    "    def sum_almost_equal(array1, array2, tol = 1e-6):\n",
    "        return sum(abs(array1 - array2)) < tol\n",
    "\n",
    "    p1 = Perceptron1(np.array([1, 1, 1]), 0)\n",
    "    p1.update(np.array([[2, 0, -3]]), np.array([1]))\n",
    "    assert sum_almost_equal(p1.weights, np.array([1.2, 1, 0.7]))\n",
    "\n",
    "    p2 = Perceptron1(np.array([1, 2, 3]), 0)\n",
    "    p2.update(np.array([[3, 2, 1], [4, 0, -1]]), np.array([0, 0]))\n",
    "    assert sum_almost_equal(p2.weights, np.array([0.7, 1.8, 2.9]))\n",
    "\n",
    "    p3 = Perceptron1(np.array([3, 0, 2]),0)\n",
    "    p3.update(np.array([[2, -2, 4],[-1, -3, 2], [0, 2, 1]]), np.array([0, 1, 0]))\n",
    "    assert sum_almost_equal(p3.weights, np.array([2.7, -0.3, 1.7]))\n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Multi Layer Perceptron \n",
    "\n",
    "The simple single node perceptron can only separate the data linearly. Multi Layer Perceptron is more useful in practice. This class of networks consists of multiple layers of computational units. Each neuron in one layer has directed connections to the neurons of the subsequent layer. In many applications the units of these networks apply a sigmoid function as an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QUESTION: \n",
    "\n",
    "Given weights for the hidden layer [1, 1, -5] and [3, -4, 2], and weights for the output layer [2, -1], what will the network output if inputs are [1, 2, 3] (as shown by the figure below)? \n",
    "\n",
    "**Answer:**  \n",
    "\n",
    "![multilayer](./img/Q_multilayer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build an XOR network  \n",
    "\n",
    "**The XOR (exclusive OR) problem** is a problem that can be described with the logic table below, and visualised in input space: \n",
    "\n",
    "![XOR](./img/XOR.png)\n",
    "\n",
    "A two-layer neural network is capable of calculating XOR. The numbers within the neurons represent each neuron's explicit threshold (which can be factored out so that all neurons have the same threshold, usually 1). The numbers that annotate arrows represent the weight of the inputs. This net assumes that if the threshold is not reached, zero (not -1) is output.   \n",
    "In this example, let's build a network capable of modeling XOR funtion. The weights and thresholds are given below.  \n",
    "\n",
    "![Q_XOR](./img/Q_XOR.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----------\n",
    "#\n",
    "# In this exercise, you will create a network of perceptrons that can represent\n",
    "# the XOR function based on the network above.\n",
    "#\n",
    "# You will need to create a network of perceptrons with the correct weights,\n",
    "# and define a procedure EvalNetwork() which takes in a list of inputs and\n",
    "# outputs the value of this network.\n",
    "#\n",
    "# ----------\n",
    "\n",
    "\n",
    "# Step 1: Set up the perceptron network\n",
    "Network = [\n",
    "    # TODO: input layer, declare input layer perceptrons here\n",
    "    [...],\n",
    "    # TODO: output node, declare output layer perceptron here\n",
    "    [...]\n",
    "]\n",
    "\n",
    "# Step 2: Define a procedure to compute the output of the network, given inputs\n",
    "def EvalNetwork(inputValues, Network):\n",
    "    \"\"\"\n",
    "    Takes in \n",
    "    @param inputValues, a list of input values, and \n",
    "    @param Network, specifies a perceptron network. \n",
    "    @return the output of the Network for the given set of inputs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # TODO: calculate the OutputValue\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def test():\n",
    "    \"\"\"\n",
    "    A few tests to make sure that the perceptron class performs as expected.\n",
    "    \"\"\"\n",
    "    EvalNetwork(np.array([0, 0]), Network) # 0 XOR 0 = 0 \n",
    "    EvalNetwork(np.array([0, 1]), Network) # 0 XOR 1 = 1 \n",
    "    EvalNetwork(np.array([1, 0]), Network) # 1 XOR 0 = 1 \n",
    "    EvalNetwork(np.array([1, 1]), Network) # 1 XOR 1 = 0 \n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III. Perceptron with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import perceptron\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mass</th>\n",
       "      <th>Length</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mass  Length  Class\n",
       "0  10.0     6.0      0\n",
       "1  20.0     5.0      0\n",
       "2   4.6     4.0      1\n",
       "3   2.0     5.0      1\n",
       "4   3.0     4.5      1\n",
       "5   3.0     6.0      0\n",
       "6  10.0     7.0      0\n",
       "7  15.0     8.0      0\n",
       "8   5.0     9.0      0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make up some data\n",
    "data = pd.DataFrame.from_items([\n",
    "    ('Mass',   [10.0, 20.0, 4.6, 2.0, 3.0, 3.0, 10.0, 15.0, 5.0]), \n",
    "    ('Length', [6.0,  5.0,  4.0, 5.0, 4.5, 6.0, 7.0,  8.0,  9.0]),\n",
    "    ('Class',  [0, 0, 1, 1, 1, 0, 0, 0, 0])])\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1a1545cad0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDDMzS+LAMDOzJA4MMzNL4sAwM7Mk/wV1GiHxm+edjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1521ad50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: plot data using Length as x-axis and Mass as y-axis \n",
    "# and use color to distinguish two classes\n",
    "class_colors = np.array(['b', 'r'])\n",
    "plt.scatter(x=data['Length'], y=data['Mass'], c=class_colors[data.Class])\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Mass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights = [[-0.004  -0.0012]]\n",
      "bias = [ 0.024]\n"
     ]
    }
   ],
   "source": [
    "# train a perceptron model \n",
    "# Create perceptron object \n",
    "p = perceptron.Perceptron(max_iter=1000, verbose=0, \\\n",
    "                          random_state=42, fit_intercept=True, eta0=0.001)\n",
    "\n",
    "# Train the perceptron object \n",
    "p.fit(data[['Length', 'Mass']], data['Class'])\n",
    "\n",
    "# Print the weights and bias\n",
    "weights = p.coef_\n",
    "bias = p.intercept_\n",
    "print \"weights = \" + str(weights)\n",
    "print (\"bias = \" + str(bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make prediction for new data (length 11 and mass 12)\n",
    "prediction = p.predict([[11, 12]])\n",
    "print prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: plot decision boundary for the training data\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
